{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='train', transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_size = int(0.80 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "trainset, valset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='test', transform=transform)\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet152(weights=True)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "num_ftrs = resnet.fc.in_features\n",
    "\n",
    "resnet.fc = nn.Sequential( \n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(32),\n",
    "    nn.Linear(32, len(train_dataset.classes))\n",
    ")\n",
    "print(num_ftrs)\n",
    "resnet.add_module('softmax', nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.0005, weight_decay=0.05)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, min_lr = 1e-6, verbose=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.535, Training Accuracy: 49.62%, Validation Loss: 1.107, Validation Accuracy: 87.59% Current lr: 0.0005\n",
      "accuracy on testing 78.5\n",
      "Epoch 2, Training Loss: 0.950, Training Accuracy: 86.50%, Validation Loss: 0.976, Validation Accuracy: 92.86% Current lr: 0.0005\n",
      "accuracy on testing 86.0\n",
      "Epoch 3, Training Loss: 0.738, Training Accuracy: 92.91%, Validation Loss: 0.860, Validation Accuracy: 94.74% Current lr: 0.0005\n",
      "accuracy on testing 88.0\n",
      "Epoch 4, Training Loss: 0.608, Training Accuracy: 95.40%, Validation Loss: 0.788, Validation Accuracy: 95.49% Current lr: 0.0005\n",
      "accuracy on testing 87.0\n",
      "Epoch 5, Training Loss: 0.528, Training Accuracy: 96.46%, Validation Loss: 0.715, Validation Accuracy: 96.99% Current lr: 0.0005\n",
      "accuracy on testing 90.5\n",
      "Epoch 6, Training Loss: 0.466, Training Accuracy: 97.36%, Validation Loss: 0.690, Validation Accuracy: 97.37% Current lr: 0.0005\n",
      "accuracy on testing 91.0\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted_train = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    # Validation phase\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted_val = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted_val == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(valloader)\n",
    "    scheduler.step(val_loss)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    \n",
    "    print('Epoch %d, Training Loss: %.3f, Training Accuracy: %.2f%%, Validation Loss: %.3f, Validation Accuracy: %.2f%%' %\n",
    "          (epoch + 1, train_loss, train_accuracy, val_loss, val_accuracy), \"Current lr:\", optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = resnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(\"accuracy on testing\", accuracy)\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 200 test images: 91.00 %\n"
     ]
    }
   ],
   "source": [
    "total_percentage = 0\n",
    "n_runs = 1\n",
    "for i in range(n_runs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = resnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    total_percentage += accuracy\n",
    "print('Accuracy of the network on the %d test images: %.2f %%' % (total, total_percentage/n_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
