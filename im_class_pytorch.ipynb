{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),  # Randomly crop the image and resize it to 224x224\n",
    "#     transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "#     transforms.RandomRotation(10),      # Randomly rotate the image by a maximum of 10 degrees\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n",
    "#     transforms.ToTensor(),              # Convert the image to a PyTorch tensor\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image using ImageNet mean and standard deviation\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='train', transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# train_size = int(0.9 * len(train_dataset))\n",
    "# val_size = len(train_dataset) - train_size\n",
    "# trainset, valset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='test', transform=transform)\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# valloader = DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet152(weights=True)\n",
    "# Freeze convolutional layers\n",
    "# Get the total number of layers in the model\n",
    "\n",
    "# Freeze all parameters initially\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_classes = 8\n",
    "# Modify fully connected layers\n",
    "num_ftrs = resnet.fc.in_features\n",
    "print(num_ftrs)\n",
    "\n",
    "#resnet.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "resnet.fc = nn.Sequential(\n",
    " #   nn.Flatten(),                               # Flatten the output of the previous layer\n",
    "    nn.Linear(num_ftrs, 128),                   # Adjust the size of the first fully connected layer\n",
    "    nn.ReLU(),        \n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Dropout(0.5),                            # Dropout layer for regularization\n",
    "    nn.Linear(128, num_classes),                # Output layer with the number of classes                           # Softmax activation to convert raw scores into probabilities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=4, min_lr = 1e-7, verbose=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, validation loss: 1.341, validation accuracy: 63.33% Current lr: 0.001\n",
      "Epoch 2, validation loss: 1.213, validation accuracy: 67.50% Current lr: 0.001\n",
      "Epoch 3, validation loss: 1.393, validation accuracy: 64.17% Current lr: 0.001\n",
      "Epoch 4, validation loss: 1.352, validation accuracy: 64.17% Current lr: 0.001\n",
      "Epoch 5, validation loss: 1.519, validation accuracy: 65.83% Current lr: 0.001\n",
      "Epoch 6, validation loss: 1.527, validation accuracy: 65.83% Current lr: 0.001\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 7, validation loss: 1.509, validation accuracy: 68.33% Current lr: 0.0001\n",
      "Epoch 8, validation loss: 1.549, validation accuracy: 65.83% Current lr: 0.0001\n",
      "Epoch 9, validation loss: 1.480, validation accuracy: 67.50% Current lr: 0.0001\n",
      "Epoch 10, validation loss: 1.606, validation accuracy: 68.33% Current lr: 0.0001\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(testloader)\n",
    "    scheduler.step(val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print('Epoch %d, validation loss: %.3f, validation accuracy: %.2f%%' %\n",
    "          (epoch + 1, val_loss, val_accuracy), \"Current lr:\", optimizer.param_groups[0]['lr'])\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 120 test images: 68.33 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Accuracy of the network on the %d test images: %.2f %%' % (total, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
